{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# calculate checksum of a file\n",
    "def calculate_checksum(file_path, algo='md5', buf_size=8192):\n",
    "    hash_algo = hashlib.new(algo)\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while chunk := f.read(buf_size):\n",
    "            hash_algo.update(chunk)\n",
    "    return hash_algo.hexdigest()\n",
    "\n",
    "# get file info (size and checksum)\n",
    "def get_file_info(folder_path):\n",
    "    file_info = {}\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            size = os.path.getsize(file_path)\n",
    "            checksum = calculate_checksum(file_path)\n",
    "            file_info[file_path] = (size, checksum)\n",
    "    return file_info\n",
    "\n",
    "# detect potential copied files\n",
    "def find_copied_files(file_info):\n",
    "    size_checksum_map = defaultdict(list)\n",
    "    for file_path, (size, checksum) in file_info.items():\n",
    "        size_checksum_map[(size, checksum)].append(file_path)\n",
    "    \n",
    "    copied_files = {key: paths for key, paths in size_checksum_map.items() if len(paths) > 1}\n",
    "    return copied_files\n",
    "\n",
    "# plot file size distribution\n",
    "def plot_file_size_distribution(file_info):\n",
    "    sizes = [size for _, (size, _) in file_info.items()]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(sizes, bins=50, kde=True)\n",
    "    plt.title('File Size Distribution')\n",
    "    plt.xlabel('File Size (bytes)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plagiarism_check(folder_path):\n",
    "    file_info = get_file_info(folder_path)\n",
    "    copied_files = find_copied_files(file_info)\n",
    "    \n",
    "    if copied_files:\n",
    "        print(\"Potential copied files found:\")\n",
    "        for (size, checksum), files in copied_files.items():\n",
    "            print(f\"\\nFiles with size {size} bytes and checksum {checksum}:\")\n",
    "            for file in files:\n",
    "                print(f\"  - {file}\")\n",
    "    else:\n",
    "        print(\"No potential copied files detected.\")\n",
    "        plot_file_size_distribution(file_info)\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'Assignments'  # Replace with the path to the google drive zip\n",
    "plagiarism_check(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
